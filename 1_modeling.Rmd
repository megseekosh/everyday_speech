---
title: "Script to replicate analyses in `Bursty, irregular speech input to preschoolers predicts vocabulary size'"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  bookdown::pdf_document2:
    keep_tex: true
indent: true
toc: false
header-includes:
 \usepackage{float}
 \floatplacement{figure}{H}
---

```{r setup, include=FALSE}
library('ggplot2')
library('bookdown')
library('lmerTest')
library('kableExtra')
library('lme4')
library('knitr')
library('dplyr')
library('tidyverse')
library('lubridate')
library('zoo')
library('gridExtra')
library('stringr')
library('viridis')
library('broom')
library('tibble')
library('zoo')
library('stargazer')
library('effects')

opts_chunk$set(echo = TRUE,warning=FALSE,error=FALSE,message=FALSE)

```

# Read in data

```{r, read in demographic and score info,cache=TRUE}
# need GSVs because we are comparing across different versions of the test 
# vocab was only assessed 1x in Romeo but 2x in l2t
# we don't have demographic data from 100R so that child will be excluded during merge
no_romeo <- c('108R','126R','132R','138R','148R','150R','152R','155R','156R','157R','178R') # Research IDs for the kids that don't have LENA 
pre_romeo_demo <- read.csv('FACT_data_cleaned.csv') %>%
    mutate(link_id = substr(FACT_ID,6,8)) %>% # get child_id to link to LENA data
    mutate(child_id = paste0(link_id,'RTP1')) %>% 
    mutate(ResearchID=paste0(link_id,'R')) %>%
    filter(!ResearchID %in% no_romeo) %>% # remove the kids w/o LENA
    mutate(PPVT_Age=Age*12) %>% # convert to mos
    mutate(Race=recode(as.factor(Race),
                      `1`='american_indian_alaskan_native',
                      `2`='asian',
                      `3`='native_hawaiian_pacific_islander',
                      `4`='black',
                      `5`='white',
                      `6`='more_than_one_race',
                      `7`='unknown')) %>%
    mutate(Ethnicity=recode(as.factor(Ethnicity),
                      `1`='not_hispanic',
                      `2`='hispanic',
                      `3`='unknown')) 


# get a dataframe with childIDs and ResearchIDs
ids <- read.csv('../dataframes/everyday_ctc.csv') %>%
    select(-X) %>%
    mutate(ResearchID=substr(child_id,1,4)) %>%
    distinct_at(., vars(ResearchID, child_id))

romeo_demo <- pre_romeo_demo %>%
  select(-child_id) %>%
  merge(., ids, by='ResearchID') %>%
  select(child_id, ResearchID, PPVT_GSV,PPVT_Age,maternal_education_level,Female,Race,Ethnicity)


tp1_vocab <- read.csv('participantinfo_tp1-2.csv') %>% 
  mutate(child_id = paste0(ResearchID,'TP1')) %>% 
  select(child_id, ResearchID, Study, PPVT_GSV, PPVT_Age) 

l2t_vocab <- read.csv('ParticipantInfo_TP2.csv') %>%
    mutate(child_id = paste0(ResearchID,'TP2')) %>% 
    select(child_id, ResearchID, Study, PPVT_GSV, PPVT_Age)

# we use maternal_education_level_revised because we couldn't distinguish between GED and HS and associate's vs some college in Rachel's data
l2t_demo <- read.csv('ParticipantInfo_TP2.csv') %>%
    select(ResearchID, maternal_education_level_revised, Female, Race, Ethnicity) %>%
    rename(maternal_education_level=maternal_education_level_revised)

tp1_complete <- l2t_demo %>% merge(., tp1_vocab, by='ResearchID') 
tp2_complete <- l2t_demo %>% merge(., l2t_vocab, by='ResearchID') 

# kids from dialect switch study
dial <- read.csv('dialect_demo_info.csv') %>%
    select(child_id, PPVT_GSV, PPVT_Age, Female, maternal_education_level, Race, Ethnicity) %>%
    mutate(ResearchID=child_id) %>%
    mutate(Study='dialect')

# kids from Mispron study
mated <- read.csv('mp_demo_info.csv') %>%
    select(child_id, PPVT_GSV, PPVT_Age, Female, maternal_education_level, Race, Ethnicity) %>%
    mutate(ResearchID=child_id) %>%
    mutate(Study="mated")


# put together 
l2t_demo <- tp1_complete %>%
  rbind(., tp2_complete) %>%
  rbind(., dial) %>%
  rbind(., mated)

write.csv(romeo_demo, '../dataframes/romeo_demo.csv')
write.csv(l2t_demo, '../dataframes/l2t_demo.csv')
```

```{r, read in LENA data,cache=TRUE}
# dataframes containing LENA data
its_df <- read.csv('../dataframes/everyday_its.csv') %>%
  select(-X)

pre_ctc <- read.csv('../dataframes/everyday_ctc.csv') %>%
    select(-X)

pre_ctc_romeo <- pre_ctc %>%
  filter(corpus=='R') %>%
  mutate(Study='Romeo') %>%
  merge(., romeo_demo, by=c('child_id'))

pre_ctc_l2t <- pre_ctc %>%
  filter(corpus!='R') %>%
  merge(., l2t_demo, by=c('child_id'))

ctc_df <- pre_ctc_romeo %>% 
  rbind(pre_ctc_l2t) %>%
  mutate(mins = (seconds/60)) %>% # divide by 60 (to get minutes) and round to the nearest 5
  mutate(epochs=round(mins/5)*5)

pre_speech <- read.csv('../dataframes/everyday_speech.csv') %>%
    select(-X)

pre_speech_romeo <- pre_speech %>%
  filter(corpus=='R') %>%
  mutate(Study='Romeo') %>%
  merge(., romeo_demo, by=c('child_id'))

pre_speech_l2t <- pre_speech %>%
  filter(corpus!='R') %>%
  merge(., l2t_demo, by=c('child_id'))

speech_df <- pre_speech_romeo %>% 
  rbind(pre_speech_l2t) 

# the LENA dataframes with CDS info
pre_pre_cds <- read.csv('../dataframes/everyday_cds_ods.csv') %>%
  #filter(cds_pred=='1') %>% # select only those epochs that are predicted to contain CDS
  filter(corpus!='E' & corpus!='J' & corpus!='A') %>% # remove Jessica's kids and kids w CIs (E & A)
  filter(!child_id %in% c('679LTP1','679LTP2','665LTP1','665LTP2','608LTP1','608LTP2','605LTP2','605LTP1', '079LTP1')) %>% # remove addtl kids w/ CIs
  filter(total_hrs>5) %>% # these recordings and the next child are removed in later processing 
  filter(child_id!='015LTP2') 

pre_cds_romeo <- pre_pre_cds %>%
  filter(corpus=='R') %>%
  mutate(Study='Romeo') %>%
  merge(., romeo_demo, by=c('child_id')) 

pre_cds_l2t <- pre_pre_cds %>%
  filter(corpus!='R') %>%
  merge(., l2t_demo, by=c('child_id'))

pre_cds <- pre_cds_romeo %>% 
  rbind(pre_cds_l2t) # 555 recordings here

# we're going to remove sleep and ODS epochs (during python processing), but first let's compute some summary statistics about them
# hours of sleep removed
pre_sleep_stats <- pre_cds %>%
  filter(sleep_pred=='1') #  552 recordings here because there wasn't sleep in one

sleep_stats <- pre_sleep_stats %>%
  group_by(child_id) %>%
  summarize(est_hours_sleep=(n()*5)/60) %>%
  summarize(avg_hrs=mean(est_hours_sleep),
            sd_hrs=sd(est_hours_sleep))

# range of probabilities in 'sleep' epochs
sleep_stats2 <- pre_sleep_stats %>%
  summarize(mean_sleep_prob=mean(sleep_prob),
            sd_sleep_prob=sd(sleep_prob))

# range of probabilities in 'cds' epochs
cds_stats <- pre_cds %>%
  filter(cds_pred=='1' & sleep_pred=='0') %>%
  summarize(mean_cds_prob=mean(cds_prob),
            sd_cds_prob=sd(cds_prob))

# average % of epochs classified as CDS
cds_perc <- pre_cds %>%
  filter(sleep_pred=='0') %>%
  group_by(child_id) %>%
  mutate(total_nonspeech_epochs=n()) %>%
  filter(cds_pred=='1') %>%
  group_by(child_id) %>%
  summarize(percen_cds_epochs=n()/total_nonspeech_epochs) %>%
  ungroup() %>%
  summarize(mean_percen_cds=mean(percen_cds_epochs),
            sd_percen_cds=sd(percen_cds_epochs))

cds_df <- pre_cds %>%
   filter(!sleep_pred=='1') # remove sleep epochs now
```

```{r, sanity check the participants,cache=TRUE}
num_ctc <- ctc_df %>% 
  distinct_at(., vars(child_id), .keep_all = T) %>%
  #filter(corpus=='R') %>% # to check individual corpora
  select(child_id) %>%
  nrow()
print(paste('There should be 564 recordings and there are', num_ctc))

num_speech <- speech_df %>% 
  distinct_at(., vars(child_id), .keep_all = T) %>%
  #filter(corpus=='R') %>% # to check individual corpora
  select(child_id) %>%
  nrow()
print(paste('There should be 564 recordings and there are', num_speech))

num_cds <- cds_df %>% 
  distinct_at(., vars(child_id), .keep_all = T) %>%
  #filter(corpus=='R') %>% # to check individual corpora
  select(child_id) %>%
  nrow()
print(paste('There should be 555 recordings and there are', num_cds)) 
```

```{r, process dataframes with nap and cds information, eval=FALSE}
# read in the dataframes containing a a Boolean for +/-1 sleep for every minute of each recording
# you will not be able to replciate this chunk of code outside of our lab, but we do share the full, generated dataframe 
# that the chunk generates 
sleep_cds_min_df <- plyr::ldply( .data = list.files(pattern="*CDS_classified.csv", # info about recording and child
                                    recursive=TRUE),
                    .fun = read.csv,
                    colClasses=c("id"="character")) %>%
  select(cds_pred,sleep_pred,cds_prob,id,Duration_Secs,segment) %>%
  mutate(onset=Duration_Secs*segment,
         offset=onset+60) # compute absolute onset timestamp; all clips are 60 seconds

write.csv(sleep_cds_min_df, '../dataframes/sleep_cds_min.csv')
```

```{r, remove naps,cache=TRUE}
# naps have already been removed from the cds dataframe (by epochs, not minutes as they will be here)
# so this is just for speech and CTC dataframes

sleep_df <- read.csv('../dataframes/sleep_cds_min.csv') %>%
  mutate(corpus = substring(id, 4, 4)) %>% # create a variable for corpus  
  filter(corpus!='E' & corpus!='J' & corpus!='A') %>% # remove Jessica's kids and kids w CIs (E & A)
  filter(!id %in% c('679LTP1','679LTP2','665LTP1','665LTP2','608LTP1','608LTP2','605LTP2','605LTP1', '079LTP1')) # remove addtl kids w/ CIs 
  
# if a timestamp falls between the timestamp of sleep, remove it
speech_df_rmv <- sleep_df %>%
  select(id,onset,sleep_pred) %>%
  rename(child_id=id,
         seconds=onset) %>%
  merge(speech_df, by=c('child_id','seconds'),all = T) %>% # impute the missing rows in speech_df
  filter(sleep_pred=='0') 
speech_df <- speech_df_rmv

ctc_df_rmv <- sleep_df %>%
  select(id,onset,sleep_pred) %>%
  rename(child_id=id,
         seconds=onset) %>%
  merge(ctc_df, by=c('child_id','seconds'),all = T) %>% # impute the missing rows
  filter(sleep_pred=='0')
ctc_df <- ctc_df_rmv

```

```{r, remove recordings less than 5 hours}
# results in removing 7 recordings 
ctc_df <- ctc_df %>%
  filter(total_hrs>5)

# also remove 015LTP2 because it was mislabeled
# as the wrong child on the .its file so it's
# unclear who was recorded that day
ctc_df <- ctc_df %>%
  filter(child_id!='015LTP2')

num_ctc <- ctc_df %>% 
  distinct_at(., vars(child_id), .keep_all = T) %>%
  select(child_id) %>%
  nrow()

num_child <- ctc_df %>% 
  distinct_at(., vars(ResearchID), .keep_all = T) %>%
  nrow()

print(paste('There should be 555 recordings and there are', num_ctc))
print(paste('There should be 292 children and there are', num_child))

# results in removing 7 recordings 
speech_df <- speech_df %>%
  filter(total_hrs>5) %>%
  filter(child_id!='015LTP2')

num_speech <- speech_df %>% 
  distinct_at(., vars(child_id), .keep_all = T) %>%
  select(child_id) %>%
  nrow()

print(paste('There should be 555 recordings and there are', num_speech))

# this code was already run above; results in removing 7 recordings 
#cds_df <- cds_df %>% 
#  filter(total_hrs>5) %>%
#  filter(child_id!='015LTP2')

num_cds <- cds_df %>% 
  distinct_at(., vars(child_id), .keep_all = T) %>%
  select(child_id) %>%
  nrow()

print(paste('There should be 555 recordings and there are', num_cds))

```


# Demo info
```{r, make demo info table, eval=FALSE}
child_list <- ctc_df %>%  
  select(ResearchID, child_id,gender,maternal_education_level,age_mos, Race,Ethnicity,PPVT_GSV,PPVT_Age) %>%
  mutate(tpt=substring(child_id,5,8)) %>%
  group_by(ResearchID) %>%
  arrange(tpt) %>%
  slice(1) # to make sure we get the age at study enrollment

num_child <- child_list %>% nrow()

gender <- child_list %>%
  group_by(gender) %>%
  count(gender) 

num_multiling <- pre_romeo_demo %>%
  filter(Multilingual>=2) %>%
  nrow()
print(paste(num_multiling,'were acquiring another language besides English', round(num_multiling/num_child,4)*100, '%'))

mat_ed_demo <- child_list %>%
  ungroup() %>%
  filter(maternal_education_level!='NA') %>%
  # reclassify the levels so we can compute correct numeric stats
  mutate(maternal_education_level=plyr::revalue(as.factor(maternal_education_level), c("3"="2", "4"="3", "6"="4", "7"="5")),
         maternal_education_level=as.numeric(maternal_education_level)) %>%
  summarize(mat_ed = mean(maternal_education_level,na.rm=TRUE),
            mat_ed_sd = sd(maternal_education_level,na.rm=TRUE),
            mat_ed_min = min(maternal_education_level,na.rm=TRUE),
            mat_ed_max = max(maternal_education_level,na.rm=TRUE)) #%>%
  mutate_if(is.numeric, round, 2) %>%
  mutate(Mat_ed=paste0(mat_ed,'(',mat_ed_sd,')',',',mat_ed_min,'-',mat_ed_max)) %>%
  select(Mat_ed)
  

# households within each maternal education level
mat_ed_dist <- child_list %>%
  ungroup() %>%
  count(maternal_education_level)

age_demo <- child_list %>%
  summarize(age = mean(age_mos),
            age_sd = sd(age_mos),
            age_min = min(age_mos),
            age_max = max(age_mos)) #%>%
  mutate_if(is.numeric, round, 2) %>%
  mutate(age=paste0(age, '(', age_sd, ')', ',',age_min, '-', age_max)) %>%
  select(age) 

no_mat_ed <- child_list %>%
  mutate(maternal_education_level=str_replace_na(maternal_education_level,"NA")) %>%
  filter(maternal_education_level=='NA') %>%
  nrow()

# race & ethnicity
ethnicity <- child_list %>%
  count(Ethnicity)

race <- child_list %>%
  group_by(Race)
  count(Race)
no_race <- race %>%
  mutate(Race=str_replace_na(Race,"NA")) %>%
  filter(Race=='unknown' | Race=='other' | Race=='no_response' | Race=='NA') 

print(paste('There were', num_child, 'unique children'))

print(paste('Mat ed unreported for', no_mat_ed, 'children'))

print(paste('Race/ethnicity information unavailable for', sum(no_race$n), 'children'))
```

# Recording info
```{r, derive descriptive stats about recordings, eval=FALSE}
recording_hrs <- ctc_df %>%
  distinct(child_id, .keep_all = T) %>%
  group_by(round(age_mos,2)) %>%
  summarize(hrs=sum(total_hrs)) 

print(paste('There were', round(sum(recording_hrs$hrs),2), 'total hours of observation'))

avg_recording_child <- ctc_df %>%
  distinct(child_id, .keep_all = T) %>%
  group_by(ResearchID) %>%
  summarize(avg_obs=sum(total_hrs))

print(paste('There was an average of', round(mean(avg_recording_child$avg_obs),2), 'hours of observation/child'))

recording_ct <- ctc_df %>%
  distinct(child_id, .keep_all = T) %>%
  count(ResearchID) 

mul_recordings <- recording_ct %>%
  filter(n>1) %>%
  distinct(ResearchID) %>%
  nrow()

print(paste(mul_recordings, 'children completed multiple recordings'))

three_four <- recording_ct %>%
  filter(n>2) %>%
  distinct(ResearchID,.keep_all = T) %>%
  nrow()

print(paste(three_four, 'children completed at least 3 recordings', round(three_four/num_child,4)*100, '%'))

two <- recording_ct %>%
  filter(n==2) %>%
  distinct(ResearchID, .keep_all = T) %>%
  nrow()

print(paste(two, 'children completed 2 recordings', round(two/num_child,4)*100, '%'))

no_vocab <- child_list %>%
  mutate(PPVT_GSV=str_replace_na(PPVT_GSV,"NA")) %>%
  filter(PPVT_GSV=='NA') %>%
  nrow()

print(paste(num_child-no_vocab, 'children had a vocabulary assessment', round((num_child-no_vocab)/num_child,4)*100, '%'))

```

```{r, recording_hrs_age}
ctc_df %>%
  distinct(child_id, .keep_all = T) %>%
  mutate(age_round=round(age_mos,1)) %>%
  group_by(age_round) %>%
  summarize(hrs_by_age=sum(total_hrs)) %>%
  rename(`Age (mos)`=age_round) %>%
  ggplot(., aes(`Age (mos)`, hrs_by_age,fill=`Age (mos)`)) +
  #geom_jitter(aes(color="#E7298A", fill="#E7298A"),size=3.8,width = .3, alpha=.75) +
  geom_bar(stat='identity') +
  xlab("Child age (mos)") +
  ylab("# of hours of observation") + 
  scale_y_continuous(breaks=seq(0, 400, by=50)) +
  scale_x_continuous(breaks=seq(0, 90, by=10)) +
  theme_minimal() + 
  theme(axis.title = element_text(face ="bold", size=17),
        legend.position = "none", 
        axis.text = element_text(face="bold", color='gray50', size=14),
        strip.text=element_text(face='bold', size=15))
```

# Compute burstiness in child-directed speech input

```{r, compute burstiness of cds using neurodsp measures}
# read the df with burstiness measures back in

# remember here that PPVT scores will be the same for all TPs in Romeo
# because vocab was only assessed 1x
cds_df2 <- cds_df %>%
  group_by(child_id) %>%
  mutate(total_words=sum(AWC_COUNT)) %>%
  distinct(., child_id, .keep_all = T) %>%
  mutate(avg_hrly_words=total_words/total_hrs) 

# this dataframe was generated with burst_detection_v1.py
# bursts were calculated over AWC words in 5-minute CDS segments with naps removed
researchid <- cds_df %>% select(child_id,ResearchID)
burst_df <- read.csv('../dataframes/burstiness_compiled_results.csv') %>%
  merge(., researchid, by='child_id') # get researchID

# merge it with the demographic data
burst_df2 <- cds_df2 %>%
  distinct(., child_id, .keep_all = T) %>%
  select(child_id, ResearchID, total_hrs, age_mos, PPVT_GSV, PPVT_Age, Female, maternal_education_level,avg_hrly_words) %>%
  merge(., burst_df, by=c('child_id','ResearchID')) %>%
  distinct(., child_id, .keep_all = T) 
```

# Table with descriptive stats about recordings

```{r, make recording stat table}
all_speech_quantity_tbl <- burst_df2 %>%
  distinct(child_id, .keep_all = T) %>%
  summarize(avg_recording_length=round(mean(total_hrs),2),
            sd_recording_length=round(sd(total_hrs),2),
            range_recording_length=paste0(round(min(total_hrs),2),'-',max(total_hrs)),
            
            avg_burst_len=round(mean(mean_burst_length)),
            sd_burst_len=round(sd(mean_burst_length)),
            range_burst_len=paste0(round(min(mean_burst_length),2),'-',round(max(mean_burst_length),2)),
            
            avg_burst_amp=round(mean(mean_burst_amplitude)),
            sd_burst_amp=round(sd(mean_burst_amplitude)),
            range_burst_amp=paste0(round(min(mean_burst_amplitude),2),'-',round(max(mean_burst_amplitude),2)),
            
            avg_awc=round(mean(avg_hrly_words)),
            sd_awc=round(sd(avg_hrly_words)),
            range_awc=paste0(round(min(avg_hrly_words),2),'`',round(max(avg_hrly_words),2)),
            
            avg_ppvt=round(mean(PPVT_GSV,na.rm=TRUE),2),
            sd_ppvt=round(sd(PPVT_GSV,na.rm=TRUE),2),
            range_ppvt=paste0(round(min(PPVT_GSV,na.rm=TRUE),2),'-',round(max(PPVT_GSV,na.rm=TRUE),2)))
  

kable(all_speech_quantity_tbl, booktabs=T, 
            caption= "Daylong recording descriptive statistics",
            row.names = FALSE) %>% 
  kable_styling() %>%
  kableExtra::kable_styling(latex_options = "hold_position")
```


# Does burstiness vary over development?

```{r, model relationship between age and cds burstiness}
# we need to take into account repeated measures from certain children
# so we include intercepts by child

center_scale <- function(x) {
    scale(x, scale = FALSE)
}


burst_df2 <- burst_df2 %>%
  mutate(mean_burst_length_centered=center_scale(log(mean_burst_length)),
         bursts_count_centered=center_scale(log(bursts_count)),
         mean_burst_amplitude_centered=center_scale(log(mean_burst_amplitude)),
         avg_hrly_words_centered=center_scale(log(avg_hrly_words)),
         age_mos_centered=center_scale(age_mos),
         mat_ed_centered=center_scale(maternal_education_level),
         Female=as.factor(Female))

length_baseline <- lmer(mean_burst_length_centered~Female+mat_ed_centered+(1|ResearchID),data=burst_df2)
burst_length <- lmer(mean_burst_length_centered~age_mos_centered+Female+mat_ed_centered+(1|ResearchID),data=burst_df2)
duration_test <- anova(length_baseline,burst_length) # improvement 
burst_length_sum <- lmer(mean_burst_length_centered~age_mos_centered+Female+mat_ed_centered+(1|ResearchID),data=burst_df2) %>% summary(.)


amp_baseline <- lmer(mean_burst_amplitude_centered~Female+mat_ed_centered+(1|ResearchID),data=burst_df2)
burst_amp <- lmer(mean_burst_amplitude_centered~age_mos_centered+Female+mat_ed_centered+(1|ResearchID),data=burst_df2)
amp_test <- anova(amp_baseline,burst_amp) # improvement
burst_amp_sum <- lmer(mean_burst_amplitude_centered~age_mos_centered+Female+mat_ed_centered+(1|ResearchID),data=burst_df2) %>% summary(.)


wd_baseline <- lmer(avg_hrly_words_centered~Female+mat_ed_centered+(1|ResearchID),data=burst_df2)
hrly_wds <- lmer(avg_hrly_words_centered~age_mos_centered+Female+mat_ed_centered+(1|ResearchID), data=burst_df2) 
quant_test <- anova(wd_baseline,hrly_wds) # no improvement 


AIC(wd_baseline)
AIC(burst_length)
AIC(burst_amp)
AIC(hrly_wds)

# for discssion: is the relationship between age and quantity present for a smaller age range?
burst_df2_limit <- burst_df2 %>%
  filter(age_mos < 40)

hrly_wds_limit <- lmer(avg_hrly_words_centered~age_mos_centered+Female+mat_ed_centered+(1|ResearchID), data=burst_df2_limit) # yes
```

```{r, age model summaries}
#stargazer incompatibility with lmerTest
# make model names shorter or we get thrown a bug
a <- lme4::lmer(mean_burst_amplitude_centered~age_mos_centered+Female+mat_ed_centered+(1|ResearchID),data=burst_df2) 
b <- lme4::lmer(mean_burst_length_centered~age_mos_centered+Female+mat_ed_centered+(1|ResearchID),data=burst_df2) 


stargazer(a, b,
            column.labels = c("Burst Amplitude", "Burst Duration"),
            model.names=FALSE, 
            label = "age-model",
            dep.var.caption = "", 
            dep.var.labels.include = FALSE,  
            type = "latex",
            star.cutoffs=c(0.05,0.01,0.001), 
            star.char = c("*", "**", "***"),
            title="The effect of child age on the quantity and burstiness of child-directed speech",  
            digits = 2, 
            ci = TRUE, 
            style = "all",
            order=c(4,1,2,3),
            covariate.labels = c("Intercept", "Age (mos)", "Gender:Female", "Mat. Ed."))

```

To compare how quantity and burstiness of CDS vary by child age, we fit three baseline models, each predicting a different dimension of CDS (burst amplitude, burst duration, and input quantity). Fixed effects included Child Gender and Maternal Education. To each model we added Child Age. Child Age significantly improved a model fit to burst amplitude ($\chi$^2=`r round(amp_test$Chisq[2],2)`, p=.04) and burst duration ($\chi$^2=`r round(duration_test$Chisq[2],2)`, p<.001), but not input quantity ($\chi$^2=`r round(quant_test$Chisq[2],2)`, p>.05; see Table X for model summaries). (AIC values likewise improved upon adding Child Age for burst amplitude and duration models, but not the input quantity model.) There was a negative effect of age for both the amplitude ($\beta$=`r round(burst_amp_sum$coefficients[2,1],4)`, p=`r round(burst_amp_sum$coefficients[2,5],2)`) and duration models ($\beta$=`r round(burst_length_sum$coefficients[2,1],4)`, p<.001), suggesting that the amplitude and duration of CDS bursts decrease between 2 and 7 years; however, CDS quantity does not decrease with age in this sample. 

```{r, visualize relationship between age and cds in words using model fits}
# first refit the models without the scaled variables
burst_amp_plt <- lmer(age_mos~mean_burst_amplitude+Female+mat_ed_centered+avg_hrly_words_centered+(1|ResearchID),data=burst_df2)  

effects_amp <- effect(term="mean_burst_amplitude", mod=burst_amp_plt) %>% as.data.frame(.)

burst_length_plt <- lmer(age_mos~mean_burst_length+Female+mat_ed_centered+avg_hrly_words_centered+(1|ResearchID),data=subset(burst_df2,mean_burst_length<40))  

effects_len <- effect(term="mean_burst_length", mod=burst_length_plt) %>% as.data.frame(.)

quant_plt <- lmer(age_mos~avg_hrly_words+Female+mat_ed_centered+(1|ResearchID),data=burst_df2)  

effects_quant <- effect(term="avg_hrly_words", mod=quant_plt) %>% as.data.frame(.)


amp_age_plt <- ggplot() +
  geom_jitter(data=burst_df2, aes(x=mean_burst_amplitude,y=age_mos, color=age_mos),size=2.8,width = .3, alpha=.75) +
  geom_line(data=effects_amp, aes(x=mean_burst_amplitude,y=fit), color='gray', size=2) + 
  geom_ribbon(data=effects_amp, aes(x=mean_burst_amplitude,ymin=lower,ymax=upper), fill='gray',alpha=.5) + 
  geom_rug(data=burst_df2, aes(x=mean_burst_amplitude,y=age_mos), alpha=.2, color='azure4', sides='b', length=unit(0.04, "npc"),size=.9) +
  ylab("Child age (mos)") +
  xlab("Average Burst \n Amplitude (Words)") + 
  scale_x_continuous(breaks = seq(0, 900, by = 100)) + 
  scale_y_continuous(breaks = seq(5, 90, by = 5)) +
  theme_minimal() + 
  theme(axis.title = element_text(face ="bold", size=10),
        legend.position = "none", 
        axis.text.x = element_text(face="bold", color='gray50', size=7,angle=-20),
        axis.text.y = element_text(face="bold", color='gray50', size=9),
        strip.text=element_text(face='bold', size=10))

dur_age_plt <- ggplot() +
  geom_jitter(data=subset(burst_df2,mean_burst_length<40), aes(x=mean_burst_length,y=age_mos, color=age_mos),size=2.8,width = .3, alpha=.75) +
  geom_line(data=effects_len, aes(x=mean_burst_length,y=fit), color='gray', size=2) + 
  geom_ribbon(data=effects_len, aes(x=mean_burst_length,ymin=lower,ymax=upper), fill='gray',alpha=.5) + 
  geom_rug(data=subset(burst_df2,mean_burst_length<40), aes(x=mean_burst_length,y=age_mos), alpha=.2, color='azure4', sides='b', length=unit(0.04, "npc"),size=.9) +
  #ylab("Child age (mos)") +
  xlab("Average Burst Duration \n (30-second segments)") + 
  scale_x_continuous(breaks = seq(0, 40, by = 5)) + 
  #scale_y_continuous(breaks = seq(0, 90, by = 5)) +
  theme_minimal() + 
  theme(axis.title.x = element_text(face ="bold", size=10),
        legend.position = "none", 
        axis.text.x = element_text(face="bold", color='gray50', size=7,angle=-20),
        strip.text.x=element_text(face='bold', size=10),
        axis.text.y=element_blank(),
        axis.title.y=element_blank())

quant_plt <- ggplot() +
  geom_jitter(data=burst_df2, aes(x=avg_hrly_words,y=age_mos, color=age_mos),size=2.8,width = .3, alpha=.75) +
  geom_line(data=effects_quant, aes(x=avg_hrly_words,y=fit), color='gray', size=2) + 
  geom_ribbon(data=effects_quant, aes(x=avg_hrly_words,ymin=lower,ymax=upper), fill='gray',alpha=.5) + 
  geom_rug(data=burst_df2, aes(x=avg_hrly_words,y=age_mos), alpha=.2, color='azure4', sides='b', length=unit(0.04, "npc"),size=.9) +
  #ylab("Child age (mos)") +
  xlab("Average Words of \n Child-directed Speech/Hour") + 
  scale_x_continuous(breaks = seq(0, 3500, by = 500)) + 
  #scale_y_continuous(breaks = seq(0, 90, by = 5)) +
  theme_minimal() + 
  theme(axis.title.x = element_text(face ="bold", size=10),
        legend.position = "none", 
        axis.text.x = element_text(face="bold", color='gray50', size=7,angle=-20),
        strip.text.x=element_text(face='bold', size=10),
        axis.text.y=element_blank(),
        axis.title.y=element_blank())
```

```{r, age_cds}
grid.arrange(amp_age_plt, dur_age_plt, quant_plt, ncol = 3)
```

# Relating bursty input to vocabulary

## Concurrent Vocabulary
```{r, model relationship between cds burstiness and vocabulary}
  
# here we have to remove Rachel's TP3 and TP4 recordings because vocab was only assessed at baseline (TP1/TP2)
burst_df_vocab_model <- burst_df2 %>%
  mutate(corpus=substring(child_id, 4, 4),
         tpt=substring(child_id,7,7)) %>%
  filter(!(corpus=='R' & (tpt=='3' | tpt=='4')))

baseline <- lmer(PPVT_GSV~age_mos_centered+Female+mat_ed_centered+avg_hrly_words_centered+(1|ResearchID),data=burst_df_vocab_model)

burst_length_v <- lmer(PPVT_GSV~mean_burst_length_centered+age_mos_centered+Female+mat_ed_centered+avg_hrly_words_centered+(1|ResearchID),data=burst_df_vocab_model)  
burst_length_v_sum <- lmer(PPVT_GSV~mean_burst_length_centered+age_mos_centered+Female+mat_ed_centered+avg_hrly_words_centered+(1|ResearchID),data=burst_df_vocab_model) %>% summary(.)
duration_test_v <- anova(baseline,burst_length_v) # improvement over baseline

burst_amp_v <- lmer(PPVT_GSV~mean_burst_amplitude_centered+age_mos_centered+Female+mat_ed_centered+avg_hrly_words_centered+(1|ResearchID),data=burst_df_vocab_model)  
burst_amp_v_sum <- lmer(PPVT_GSV~mean_burst_amplitude_centered+age_mos_centered+Female+mat_ed_centered+avg_hrly_words_centered+(1|ResearchID),data=burst_df_vocab_model) %>% summary(.)
amp_test_v <- anova(baseline,burst_amp_v) # improvement over baseline
```

```{r, vocab model summaries}
burst_df_vocab_model2 <- burst_df_vocab_model
burst_df_vocab_model2$bursty_measure <- burst_df_vocab_model$mean_burst_amplitude_centered
burst_df_vocab_model$bursty_measure <- burst_df_vocab_model$mean_burst_length_centered

av <- lme4::lmer(PPVT_GSV~bursty_measure+age_mos_centered+Female+mat_ed_centered+avg_hrly_words_centered+(1|ResearchID),data=burst_df_vocab_model2)

bv <- lme4::lmer(PPVT_GSV~bursty_measure+age_mos_centered+Female+mat_ed_centered+avg_hrly_words_centered+(1|ResearchID),data=burst_df_vocab_model) 


stargazer(av, bv,
            column.labels = c("Burst Amplitude", "Burst Duration"),
            model.names=FALSE, 
            label = "vocab-model",
            dep.var.caption = "", 
            dep.var.labels.include = FALSE,  
            type = "latex",
            star.cutoffs=c(0.05,0.01,0.001), 
            star.char = c("*", "**", "***"),
            title="The effect of quantity and burstiness of child-directed speech on concurrent vocabulary scores",  
            digits = 2, 
            ci = TRUE, 
            style = "all",
            order=c(6,1,2,3,4,5),
            covariate.labels = c("Intercept", "Bursty Measure", "Age (mos)", "Gender:Female", "Mat. Ed.", "Avg. Hrly Words")) 
```

Next, we compared how the quantity and burstiness of CDS predicted children's receptive vocabulary size. We first fit a baseline model with fixed effects of Child Age, Child Gender, Maternal Education, and Average Hourly CDS Words. Child Age was modeled to account for its strong relationship with word learning over this period. Hourly CDS Words was added to evaluate if the distribution of input parameters (Burst Amplitude and Burst Duration) predicted vocabulary scores beyond quantity. We fit two models to predict vocabulary scores using the two different distribution parameters. Both input distribution parameters improved their respective model fits (Burst Amplitude: $\chi$^2=`r round(amp_test_v$Chisq[2],2)`, p=.04; Burst Duration: $\chi$^2=`r round(duration_test_v$Chisq[2],2)`, p<.001). Specifically, both measures of input distribution were positive predictors of concurrent vocabulary scores (Burst Amplitude: $\beta$=`r round(burst_amp_v_sum$coefficients[2,1],2)`, p=`r round(burst_amp_v_sum$coefficients[2,5],2)`; Burst Duration: $\beta$=`r round(burst_length_v_sum$coefficients[2,1],2)`, p=`r round(burst_length_v_sum$coefficients[2,5],2)`), even after controlling for the quantity of input. See Table X for all model summaries.

```{r, visualize relationship between cds burstiness and vocabulary using model fits}
# first refit the models without the scaled variables
burst_amp_v_plt <- lmer(PPVT_GSV~mean_burst_amplitude+age_mos_centered+Female+mat_ed_centered+avg_hrly_words_centered+(1|ResearchID),data=burst_df_vocab_model)  

effects_amp_ppvt <- effect(term="mean_burst_amplitude", mod=burst_amp_v_plt) %>% as.data.frame(.)

burst_length_v_plt <- lmer(PPVT_GSV~mean_burst_length+age_mos_centered+Female+mat_ed_centered+avg_hrly_words_centered+(1|ResearchID),data=subset(burst_df_vocab_model, mean_burst_length<40))  

effects_len_ppvt <- effect(term="mean_burst_length", mod=burst_length_v_plt) %>% as.data.frame(.)

quant_v_plt <- lmer(PPVT_GSV~age_mos_centered+Female+mat_ed_centered+avg_hrly_words+(1|ResearchID),data=burst_df_vocab_model)  

effects_quant_ppvt <- effect(term="avg_hrly_words", mod=quant_v_plt) %>% as.data.frame(.)

amp_ppvt_plt <- ggplot() +
  geom_jitter(data=burst_df_vocab_model, aes(x=mean_burst_amplitude,y=PPVT_GSV, color=age_mos),size=2.8,width = .3, alpha=.75) +
  geom_line(data=effects_amp_ppvt, aes(x=mean_burst_amplitude,y=fit), color='gray', size=2) + 
  geom_rug(data=burst_df_vocab_model, aes(x=mean_burst_amplitude,y=PPVT_GSV), alpha=.2, color='azure4', sides='b', length=unit(0.04, "npc"),size=.9) +
  geom_ribbon(data=effects_amp_ppvt, aes(x=mean_burst_amplitude,ymin=lower,ymax=upper), fill='gray',alpha=.5) + 
  xlab("Average Burst \n Amplitude (Words)") +
  ylab("Receptive Vocabulary Score (PPVT GSVs)") + 
  scale_x_continuous(breaks = seq(0, 900, by = 100)) + 
  theme_minimal() + 
  theme(axis.title = element_text(face ="bold", size=10),
        legend.position = "none", 
        axis.text.x = element_text(face="bold", color='gray50', size=7,angle=-20),
        axis.text.y = element_text(face="bold", color='gray50', size=9),
        strip.text=element_text(face='bold', size=10))

len_ppvt_plt <- ggplot() + 
  geom_jitter(data=subset(burst_df_vocab_model, mean_burst_length<40), aes(x=mean_burst_length,y=PPVT_GSV, color=age_mos),size=2.8,width = .3, alpha=.75) +
  geom_line(data=effects_len_ppvt, aes(x=mean_burst_length,y=fit), color='gray', size=2) + 
  geom_rug(data=subset(burst_df_vocab_model, mean_burst_length<40), aes(x=mean_burst_length,y=PPVT_GSV), alpha=.2, color='azure4', sides='b', length=unit(0.04, "npc"),size=.9) +
  geom_ribbon(data=effects_len_ppvt, aes(x=mean_burst_length,ymin=lower,ymax=upper), fill='gray',alpha=.5) + 
  xlab("Average Burst Duration \n (30-second segments)") +
  scale_x_continuous(breaks = seq(0, 40, by = 5)) + 
  theme_minimal() + 
  theme(axis.title.x = element_text(face ="bold", size=10),
        axis.text.x = element_text(face="bold", color='gray50', size=8,angle=-20),
        strip.text.x=element_text(face='bold', size=10),
        axis.text.y=element_blank(),
        axis.title.y=element_blank(),
        legend.position = "none")

word_ppvt_plt <- 
  ggplot() + 
  geom_jitter(data=burst_df_vocab_model, aes(x=avg_hrly_words,y=PPVT_GSV, color=age_mos),size=2.8,width = .3, alpha=.75) +
  geom_line(data=effects_quant_ppvt, aes(x=avg_hrly_words,y=fit), color='gray', size=2) + 
  geom_ribbon(data=effects_quant_ppvt, aes(x=avg_hrly_words,ymin=lower,ymax=upper), fill='gray',alpha=.5) + 
  geom_rug(data=burst_df_vocab_model, aes(x=avg_hrly_words,y=PPVT_GSV), alpha=.2, color='azure4', sides='b', length=unit(0.04, "npc"),size=.9) +
  xlab("Average Words of \n Child-directed Speech/Hour") +
  scale_x_continuous(breaks = seq(0, 3500, by = 500)) + 
  theme_minimal() + 
  theme(axis.title.x = element_text(face ="bold", size=10),
        axis.text.x = element_text(face="bold", color='gray50', size=8,angle=-20),
        strip.text.x=element_text(face='bold', size=10),
        axis.text.y=element_blank(),
        axis.title.y=element_blank(),
        legend.title=element_text(face='bold',size=8),
        legend.position = c(.85,.3),
        legend.box.background = element_rect(color = "black")) +
scale_color_continuous(name = "Age (mos)")
```

```{r, cds_vocab}
grid.arrange(amp_ppvt_plt, len_ppvt_plt, word_ppvt_plt, ncol = 3)
```

# Supp. Materials II: conversational turn analysis

Here we define speech input (and interaction) using conversational turns taken between the key child and an adult. We examine whether burstiness in *turns* also relates to children's receptive vocabulary sizes. 

```{r prepare to compute the burstiness of input using conversational epochs}
# first impute epochs with 0 turns

time_steps2 <- rep(seq(0,950,5),times=555) %>% as.data.frame() 
time_steps2$epochs <- time_steps2$.

ids2 <- ctc_df %>% distinct(child_id) 
ids2_repeat <- rep(ids2$child_id,191) %>% as.data.frame()
ids2_repeat$child_id <- ids2_repeat$.
time_steps_demo <- ids2_repeat %>%
  arrange(child_id) %>%
  select(-.) %>%
  cbind(., time_steps2) %>%
  select(child_id, epochs)

pre_input_consis <- ctc_df %>%  
  select(child_id, epochs, duration, convo_count, clip_onset, segment_type, total_hrs) %>% 
  merge(., time_steps_demo, by=c('epochs', 'child_id'),all=TRUE) %>% # impute the missing epochs
  replace_na(list(duration = 0, convo_count=0)) # replace the imputed time stamps with 0 turns and 0 duration
                                                # there should *definitely* be "empty" epochs
# remove the epochs that were added erroneously to recordings < 16 hrs. 
# (fills in epochs for periods that weren't actually recorded)
pre_input_consis2 <- pre_input_consis %>%
  group_by(child_id) %>%
  mutate(total_epochs=(round((total_hrs*60)/5)*5)) %>%
  mutate(total_epochs=total_epochs-5) %>%
  group_by(child_id) %>%
  mutate(total_epochs2 = na.locf(na.locf(total_epochs,na.rm = FALSE),na.rm = FALSE)) %>% # impute a value for total epochs for the "empty" epoch rows
  filter(epochs <= total_epochs2) # remove all of the epochs that 1) are greater than the max # and 2) don't have any CTC info 
                                  # this allows us to still keep the "empty" epochs that occurred during the actual recording

turns_per_epoch <- pre_input_consis2 %>%
  group_by(child_id, epochs) %>%
  summarize(turns = sum(convo_count)) 

ctc_consis <- pre_input_consis2 %>%
  select(-duration, -convo_count, -clip_onset) %>%
  distinct_at(., vars(child_id, epochs), .keep_all = T) %>%
  merge(., turns_per_epoch, by=c('child_id', 'epochs')) 
```

```{r, boolean to classify each epoch as bursty or not}
ctc_burst <- ctc_consis %>%
  group_by(child_id) %>%
  mutate(mad_turns=mad(turns)) %>% # for each child compute the median absolute deviation
  ungroup() %>%
  mutate(bursty=if_else(turns>mad_turns*3, "bursty", "not_bursty")) %>%
  filter(bursty=='bursty') %>% # only looking at bursty epochs
  group_by(child_id) %>%
  summarize(avg_amp_ctc=mean(turns),.groups = 'keep') # compute convo amplitude as the average # of turns within bursty epochs
  
# re-merge with vocabulary information
ctc_burst2 <- burst_df2 %>%
  distinct_at(., vars(child_id, PPVT_GSV, Female, mat_ed_centered,age_mos_centered,ResearchID)) %>%
  merge(., ctc_burst, by='child_id')
```

```{r, compute descriptive statistics about bursty conversations}
ctc_burst_stats <- ctc_burst2 %>%
  summarize(mean_amp=mean(avg_amp_ctc),
            sd_amp=sd(avg_amp_ctc),
            min_amp=min(avg_amp_ctc),
            max_amp=max(avg_amp_ctc))
```

```{r, modeling relationship between bursty conversations and vocabulary}
burst_ctc_m3 <- lmer(PPVT_GSV~avg_amp_ctc+age_mos_centered+Female+mat_ed_centered+(1|ResearchID),data=ctc_burst2) 

burst_ctc_m3_sum <- summary(burst_ctc_m3)
```

## Data pre-processing

We wrote an ad-hoc script to mine the .its file associated with each LENA recording and provide us with the number of conversational turns within each 5-minute epoch of the recording. The turn count was estimated from LENA's linguistic unit algorithm, which has been reported on widely elsewhere in the literature. We imputed "empty" epochs (epochs without any conversational turns) for each recording, to reflect the times when the child was not exposed to any turns. In this supplementary analysis, we limited the computation to burst amplitude, since we didn't see large differences between burst amplitude and duration in the child-directed speech analysis in the full manuscript and also we didn't have strong apriori reasons to presume that conversational turn burst amplitude and duration would differ that much from one another. The average amplitude of bursty conversational epochs within the recordings was `r round(ctc_burst_stats$mean_amp,2)` turns (SD=`r round(ctc_burst_stats$sd_amp,2)`, range=`r paste0(round(ctc_burst_stats$min_amp,2),'-',round(ctc_burst_stats$max_amp,2))`).

## Model fitting

We fit a linear mixed effects model to predict receptive vocabulary scores (Peabody Picture Vocabulary Test-5 growth scale values) and included random intercepts of Child. We additionally included fixed effects of Child Age (in months, centered and scaled), Maternal Education (binned, as described in the manuscript, and centered and scaled), and Child Gender (contrast coded). The variable of interest was the average amplitude (number of turns) within bursty conversational epochs, which was a significant predictor of vocabulary scores ($\beta$=`r round(burst_ctc_m3_sum$coefficients[2,1],2)`, p=`r round(burst_ctc_m3_sum$coefficients[2,5],3)`; model summary in Table 1). This analysis supports the idea that bursty interaction, in this case conversational turns between the key child and an adult, is likewise positively related to concurrent receptive vocabulary scores. 

```{r, bursty conversation and vocabulary model}
turn_model <- lme4::lmer(PPVT_GSV~avg_amp_ctc+age_mos_centered+Female+mat_ed_centered+(1|ResearchID),data=ctc_burst2)  


stargazer(turn_model,
            model.names=FALSE, 
            label = "turn-model",
            dep.var.caption = "", 
            dep.var.labels.include = FALSE,  
            type = "latex",
            star.cutoffs=c(0.05,0.01,0.001), 
            star.char = c("*", "**", "***"),
            title="The relationship between bursty converstational turns and concurrent receptive vocabulary size",  
            digits = 2, 
            ci = TRUE, 
            style = "all",
            order=c(5,1,2,3,4),
            covariate.labels = c("Intercept", "Convo. Turn Amplitude", "Age (mos)", "Gender:Female", "Mat. Ed."))
```

# Supp. Materials III: overall speech analysis

Here we define input using the adult word counts from LENA's linguistic unit algorithm. That is, we do not distinguish between speech directed to the child versus someone else (child-directed speech versus other-directed speech). We examine whether burstiness in *overall speech input* (directed and overheard) also relates to children's receptive vocabulary sizes. 

```{r, prepare to compute the burstiness of overall speech input}
# compute the percentage of minutes in the child's day with > 1 AW 

time_steps <- rep(seq(60,57600,60),times=555) %>% as.data.frame() 
time_steps$seconds <- time_steps$.
ids <- speech_df %>% distinct(child_id) 
ids_repeat <- rep(ids$child_id,960) %>% as.data.frame()
ids_repeat$child_id <- ids_repeat$.
time_steps_demo <- ids_repeat %>%
  arrange(child_id) %>%
  select(-.) %>%
  cbind(., time_steps) %>%
  select(child_id, seconds)

pre_input_consis_speech <- speech_df %>%
  select(child_id, seconds, age_mos, duration, total_hrs, wordCount, clip_onset, segment_type) %>% 
  merge(., time_steps_demo, by=c('seconds', 'child_id'),all=TRUE) %>% # impute the missing seconds
  replace_na(list(duration = 0, wordCount=0)) # replace the imputed time stamps with 0 adult words and 0 duration

input_consis_speech <- pre_input_consis_speech %>%
  group_by(child_id, seconds) %>%
  summarize(adult_words = sum(wordCount)) # total num of words/minute
```

```{r, boolean to classify each minute as bursty or not}
speech_burst <- input_consis_speech %>%
  group_by(child_id) %>%
  mutate(mad_words=mad(adult_words)) %>% # for each child compute the median absolute deviation of words
  ungroup() %>%
  mutate(bursty=if_else(adult_words>mad_words*3, "bursty", "not_bursty")) %>%
  filter(bursty=='bursty') %>% # only looking at bursty minutes
  group_by(child_id) %>%
  summarize(avg_amp_speech=mean(adult_words),.groups = 'keep') # compute word amplitude as the average # of words within bursty minutes
  
# re-merge with vocabulary information
speech_burst2 <- burst_df2 %>%
  distinct_at(., vars(child_id, PPVT_GSV, Female, mat_ed_centered,age_mos_centered,ResearchID,avg_hrly_words_centered)) %>%
  merge(., speech_burst, by='child_id')
```

```{r, compute descriptive statistics about bursty overall speech}
speech_burst_stats <- speech_burst2 %>%
  summarize(mean_amp=mean(avg_amp_speech),
            sd_amp=sd(avg_amp_speech),
            min_amp=min(avg_amp_speech),
            max_amp=max(avg_amp_speech))
```

```{r, modeling relationship between bursty overall speech and vocabulary}
burst_speech_m3 <- lmer(PPVT_GSV~avg_amp_speech+age_mos_centered+Female+mat_ed_centered+avg_hrly_words_centered+(1|ResearchID),data=speech_burst2) 

burst_speech_m3_sum <- summary(burst_speech_m3)
```

## Data pre-processing

We wrote an ad-hoc script to mine the .its file associated with each LENA recording and provide us with the number of words from adults within each minute of the recording. The word count was estimated from LENA's linguistic unit algorithm, which has been reported on widely elsewhere in the literature. We imputed "empty" minutes (epochs without any adult words) for each recording, to reflect the times when the child was not exposed to any words. In this supplementary analysis, we limited the computation to burst amplitude, since we didn't see large differences between burst amplitude and duration in the child-directed speech analysis in the full manuscript so we didn't think that overall speech input burst amplitude and duration would differ that much from one another. The average amplitude of bursty overall speech within the recordings was `r round(speech_burst_stats$mean_amp,2)` words (SD=`r round(speech_burst_stats$sd_amp,2)`, range=`r paste0(round(speech_burst_stats$min_amp,2),'-',round(speech_burst_stats$max_amp,2))`). (Note that in the manuscript we performed additional interpolation and actually looked at 30-second increments, not 60-second as we do here.)

## Model fitting

We fit a linear mixed effects model to predict receptive vocabulary scores (Peabody Picture Vocabulary Test-5 growth scale values) and included random intercepts of Child. We additionally included fixed effects of Child Age (in months, centered and scaled), Maternal Education (binned, as described in the manuscript, and centered and scaled), and Child Gender (contrast coded). The variable of interest was the average amplitude (number of adult words) within bursty minutes, which did not predict vocabulary scores ($\beta$=`r round(burst_speech_m3_sum$coefficients[2,1],2)`, p=`r round(burst_speech_m3_sum$coefficients[2,5],2)`; model summary in Table 1). This analysis supports the idea that bursty overall *child-directed speech* input, is positively related to concurrent receptive vocabulary scores. However, this same effect on vocabulary may not be present for the overall speech that children are exposed to (other-directed, overheard, etc.).

```{r, bursty overall speech and vocabulary model}
speech_model <- lme4::lmer(PPVT_GSV~avg_amp_speech+age_mos_centered+Female+mat_ed_centered+avg_hrly_words_centered+(1|ResearchID),data=speech_burst2)  
stargazer(speech_model,
            model.names=FALSE, 
            label = "turn-model",
            dep.var.caption = "", 
            dep.var.labels.include = FALSE,  
            type = "latex",
            star.cutoffs=c(0.05,0.01,0.001), 
            star.char = c("*", "**", "***"),
            title="The relationship between bursty overall speech input and concurrent receptive vocabulary size",  
            digits = 2, 
            ci = TRUE, 
            style = "all",
            order=c(6,1,2,3,4,5),
            covariate.labels = c("Intercept", "Adult Word Amplitude", "Age (mos)", "Gender:Female", "Mat. Ed.", "Avg. Hourly Words"))
```


